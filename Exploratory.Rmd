---
title: "NATSAP- Exploratory Data Analysis"
author: "Sean Raleigh"
date: "July 8, 2015"
output: html_document
---

In this document, we clean the data and store it for use in other models. Then we do some basic exploratory data analysis to get to know the data better.

## Housekeeping

Load necessary libraries and special functions.

```{r, message = FALSE}
library(beepr)
library(dplyr)
library(ggplot2)
library(knitr)
library(readr)
```

```{r}
source("stan_utilities.R")

## The file stan_utilities.R contains the following functions:

########################################

## cleanup

## Cleans up the objects left over after fitting a Stan model:
##      data_model:     The data list passed to stan.
##      fit_model:      The stanfit object output.
##      samples_model:  The samples as a data frame.
##      params_model:   The parameters to track for plotting.
## Returns nothing.

## cleanup(model)

# model:                Root name of the Stan model as character string.

########################################

## HDI_calc

## Calculates HDI and prepares graphical parameters to pass to ggplot.
## Returns a list of three objects:
##      breaks:     The breaks to use for the histogram.
##      line_pos:   Parameters for plotting the HDI line segments.
##      text_pos:   Parameters for plotting the text annotations.

## HDI_calc(sample, cred_mass = 0.95, digits = 2)

# sample:           A vector of representative values from a probability distribution.
# cred_mass:        A scalar between 0 and 1, indicating the mass within the credible
#                       interval that is to be estimated.
# digits:           The number of decimal places when displaying the HDI.

########################################

## HDIofMCMC (John Kruschke)

## Computes highest density interval from a sample of representative values,
##      estimated as shortest credible interval.

## HDIofMCMC(sampleVec , cred_mass = 0.95)

# sampleVec:        A vector of representative values from a probability distribution.
# cred_mass:        A scalar between 0 and 1, indicating the mass within the credible
#                       interval that is to be estimated.

########################################

## multiplot (winston Chang)

## Places ggplot objects in a grid.
## Returns nothing, but displays desired graphics.

## multiplot(..., plotlist=NULL, file, cols=1, layout=NULL)

# ...               One can pass ggplot objects directly.
#                           (But it's easier to pass them as a plotlist.)
# plotlist:         A list of ggplot objects.
# cols:             Number of columns in layout.
#                       If layout is not specified, multiplot will calculate
#                       how many rows to create using cols.
# layout:           A layout matrix.
#                       For example:
#                           matrix(c(1,2,3,3), nrow=2, byrow=TRUE)
#                       Plot 1 will go in the upper left,
#                       plot 2 will go in the upper right, and
#                       plot 3 will go all the way across the bottom.
#                       If present, cols is ignored.

########################################

## params_per_program

## Takes a list of sampled parameters for a collection of programs and refactors
## it so that each row is a program and the columns contain summaries of the
## parameters that correspond to that program.
## Returns a data frame.

## params_per_program(df)

# df:               A data frame of MCMC samples. For this to work, program-level
#                   parameters should be of the form 'param[#]' where # is the
#                   corresponding program new_ID.

########################################

## param_plot

## Plots a sampled parameter along with HDI.
## Returns a ggplot object.

## param_plot(sample, param, cred_mass = 0.95)

# sample:           A vector of representative values from a probability distribution.
# param:            A string with the name of the parameters to be plotted.
# cred_mass:        A scalar between 0 and 1, indicating the mass within the credible
#                       interval that is to be estimated.

########################################

## sample_plots

## Creates a grid of histograms of sampled parameters with HDIs.
## Returns nothing, but displays the result of multiplot.

## sample_plots(samples, params, cred_mass = 0.95, layout = NULL)

# samples:          A data frame extracted from a stanfit object.
# params:           A character vector of parameters to be plotted.
# cred_mass:        A scalar between 0 and 1, indicating the mass within the credible
#                       interval that is to be estimated.
# layout:           A layout matrix.
#                       For example:
#                           matrix(c(1,2,3,3), nrow=2, byrow=TRUE)
#                       Plot 1 will go in the upper left,
#                       plot 2 will go in the upper right, and
#                       plot 3 will go all the way across the bottom.
#                       If present, cols is ignored.

########################################
```

## Read and process data

Load data.

```{r}
natsap <- read_csv("./data/AllClients_rev3.csv")
dose <- read_csv("./data/DoseData_07-08-2015.csv")
```

Clean data and write to the `tidydata` folder.

```{r}

## Subset data

natsap_sub <- natsap %>%
    select(sex = gender,
           ID = programId,
           company = company,
           OQ_A = Z1_A0_Self_SCORE,
           OQ_D = Z1_D0_Self_SCORE)

dose_sub <- dose %>%
    select(company = company,
           ID = NATSAP_ID,
           RTCWT = `RTC or WT`,
           IT = `Mode minutes of Inidividual Therapy per week`,
           # IT_freq = `Frequency of IT per week`,
           GT = `Mode minutes of Group Therapy per week`,
           # GT_freq = `Frequency of GT week`,
           RFT = `Mode minutes  of Remote Family Therapy per week`)
           # RFT_freq = `Frequency of RFT per week`)


## Check to make sure program IDs are coded correctly.

ID_check_natsap <- natsap_sub %>%
    distinct(ID) %>%
    select(company, ID)
ID_check_dose <- dose_sub %>%
    distinct(ID) %>%
    select(company, ID)

ID_check <- inner_join(ID_check_dose, ID_check_natsap, by = "ID")
as.data.frame(ID_check)


## Get complete cases

natsap_sub <- natsap_sub %>%
    na.omit() %>%
    filter(sex != "")
dose_sub <- dose_sub %>%
    na.omit()


## Validity check:
## OQ scores have to be between -16 and 240.

natsap_sub <- natsap_sub %>%
    filter(OQ_A >= -16 & OQ_A <= 240 & OQ_D >= -16 & OQ_D <= 240)


## Join IDs so our tidy data sets will contain only
## programs for which we have dose data and matched pairs.

natsap_tidy <- semi_join(natsap_sub, dose_sub, by = "ID")
dose_tidy <- semi_join(dose_sub, natsap_sub, by = "ID")


## Get sample sizes for each program and keep only programs with more than two 
## matched pairs

sample_size <- natsap_tidy %>%
    group_by(ID) %>%
    summarise(n = n())

dose_tidy <- dose_tidy %>%
    inner_join(sample_size, by = "ID") %>%
    filter(n > 2)

natsap_tidy <- natsap_tidy %>%
    semi_join(dose_tidy, by = "ID")


## Make OQdiff variable

natsap_tidy <- natsap_tidy %>%
    mutate(OQdiff = OQ_A - OQ_D) # Positive scores represent improvement


## Give programs new random ID, consecutively numbered

J <- NROW(dose_tidy)
set.seed(1234)
new_ID <- sample(1:J, J)

dose_tidy <- dose_tidy %>%
    cbind(new_ID) %>%
    arrange(new_ID)

lookup <- dose_tidy %>%
    select(ID, new_ID)

natsap_tidy <- natsap_tidy %>%
    inner_join(lookup, by = "ID") %>%
    arrange(new_ID)


## Write tidy data sets to csv for convenience

write_csv(dose_tidy, path = "./tidydata/dose_tidy_1.csv")
write_csv(natsap_tidy, path = "./tidydata/natsap_tidy_1.csv")


## Clean up environment
 
rm(natsap, dose, natsap_sub, dose_sub, ID_check, ID_check_dose, ID_check_natsap, J, new_ID, lookup, sample_size)
```

## Exploratory data analysis

[to do]

```{r}
beep()
```
